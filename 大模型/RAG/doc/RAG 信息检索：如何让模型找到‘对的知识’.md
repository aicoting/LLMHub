大家好，我准备开启一个全新的系列，来聊聊——RAG（Retrieval-Augmented Generation）系统的底层设计与工程实现。

<font style="color:rgb(25, 27, 31);">你可能已经用过各种“大模型加检索”的应用：AI 助手能秒答公司文档问题、客服机器人能一口气分析十几页合同、技术问答系统好像“查阅过全网资料”……但你有没有想过：这些模型到底是怎么“知道”你提的问题答案的？模型为什么能记住一整本文档？我们把知识库接入大模型，到底做了什么？</font>

<font style="color:rgb(25, 27, 31);">这一切的背后，离不开三个字母：</font>**RAG**<font style="color:rgb(25, 27, 31);">。</font>

<font style="color:rgb(25, 27, 31);">这个系列将拆解构建一个 RAG 系统的全流程，深入剖析每个关键步骤的逻辑、技术选型与工程落地难点：</font>

+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（一）：</font>[什么是RAG？一文搞懂检索增强生成技术](https://zhuanlan.zhihu.com/p/1912270367357122436)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（二）：</font>[一文搞懂RAG 的文档解析](https://zhuanlan.zhihu.com/p/1912549174966194672)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（三）：</font>[一文搞懂RAG 的切分策略](https://zhuanlan.zhihu.com/p/1912878600853623201)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（四）：</font>[RAG-embedding篇](https://zhuanlan.zhihu.com/p/1912910452339484544)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（五）：</font>[RAG信息检索-如何让模型找到‘对的知识’](https://zhuanlan.zhihu.com/p/1912920089109430794)

<font style="color:rgb(25, 27, 31);">此外，所有相关源码示例、流程图、模型配置与知识库构建技巧，我也将持续更新在 Github：</font>[**<font style="color:rgb(25, 27, 31);">LLMHub</font>**](https://github.com/zhangting-hit/LLMHub)<font style="color:rgb(25, 27, 31);">，欢迎关注收藏！</font>

## <font style="color:rgb(25, 27, 31);">1.前言</font>
RAG飞速发展，成为连接“生成能力”与“外部知识”的桥梁，关于RAG的介绍可以参考[什么是RAG？一文搞懂检索增强生成技术](https://zhuanlan.zhihu.com/p/1912270367357122436)。

前面我们介绍了RAG系统中的文档解析，[RAG 的文档解析：PDF 篇](https://zhuanlan.zhihu.com/p/1912549174966194672)，在解析文档得到数据后，由于数据规模很可能非常庞大，整体存储具有难度，并且在查询的时候可能仅仅和其中的一个或几个段落有关系，所以需要分块技术将解析后的文档内容切分为适当的片段[一分钟读懂RAG的切分策略](https://zhuanlan.zhihu.com/p/1912878600853623201)。

切分完成后，需要将内容存储到向量数据库以供后续检索[RAG-embedding篇](https://zhuanlan.zhihu.com/p/1912910452339484544)。

在RAG系统中，生成效果的好坏，往往不取决于模型本身有多“聪明”，而是它是否能“查对资料”。通俗地说，RAG 的本质是一种“开卷考试”：模型并不靠死记硬背，而是通过查找外部知识库来作答。如果查的资料靠谱、精确、上下文合理，回答自然逻辑清晰、信息详实；反之，如果检索不到关键内容，生成再强的模型也只能“睁眼说瞎话”。

## 2.embedding生成
### 2.1文档段落嵌入
在 RAG 系统中，原始文档（无论是论文、网页、PDF 还是 Markdown）首先会被切分成若干逻辑段落。这些段落随后会被送入嵌入模型中转化为**向量**，也就是一串浮点数，代表了这段话的语义特征。这个过程就叫做**文档段落嵌入**。

例如：

```plain
"气候变暖的主要原因是温室气体排放。" → [0.12, -0.38, ..., 0.77]
"新能源汽车有助于减少碳排放。" → [0.14, -0.42, ..., 0.81]
```

这两个段落的向量非常相近，因为它们都和“环境”与“碳排放”有关。

嵌入后的段落会被存储进向量数据库，为后续检索做准备。**注意：切分策略越合理，嵌入效果越稳定**。否则，一个乱七八糟的句子，即使变成向量，也不会“靠近”它真正应该靠近的知识点。

### 2.2 用户查询嵌入
用户在提问时，并不是直接丢问题给语言模型，而是先把问题送进同一个嵌入模型中，转换成查询向量。这一步称为**用户查询嵌入**。

举个例子：

```plain
用户提问：“如何减少碳排放？”
嵌入后 → [0.15, -0.41, ..., 0.79]
```

此时，系统就会在向量数据库中查找和这个查询向量**最接近的文档段落向量**，通常是 Top-K 个。比如：

+ 段落1：“推广新能源车有助于碳中和”
+ 段落2：“工业废气治理是重要手段”
+ 段落3：“碳捕捉技术日益成熟”

然后，把这些相关段落拼成上下文，送给大模型生成最终回答。

## 3、相似度检索
文档向量和查询向量都有了，接下来就是“看谁更像谁”的时刻了。这一步叫做**相似度检索**。简单来说，就是：把用户提问转成向量，然后在海量文档向量查找目标向量。

### 3.1常见检索方式
+ **Top-K 检索**：最常用的一种方式，找到与查询向量最相近的 K 个文档段落。
+ **MMR（Maximal Marginal Relevance）**：一种既考虑相关性又考虑多样性的策略。防止检索结果全是“同义句”，更利于生成丰富、全面的答案。

但是上述基础的检索方式有时候还不能满足高精度要求，于是又出现了**rerank**等检索方法。

### 3.2 Reranker 二次排序
在 RAG（Retrieval-Augmented Generation）中，初始的向量检索阶段可能会返回 **Top-K** 个“相关性还不错”的段落，但这些段落：

+ 有可能相关性不够强；
+ 有可能缺乏真正回答问题的能力；
+ 有可能风格、语义重复，影响生成效果。

于是，我们需要 **Reranker（重排序器）** —— 就像在初筛简历后，HR 还要对候选人深入面试，挑出真正合适的人。

Reranker 通常使用一个更强大的**双塔模型（bi-encoder）或交叉编码器（cross-encoder）**，对用户查询与候选文档段落进行语义匹配打分，并按照分数排序。

流程如下：

1. 用户输入问题，进行 embedding；
2. 在向量数据库中查出 Top-K 相关片段；
3. 将查询和每个候选片段组成 `<query, passage>` 对；
4. 使用 Reranker 模型对每对文本打分；
5. 按照分数排序，取前 N 个作为最终的上下文输入给 LLM。

![](https://cdn.nlark.com/yuque/__mermaid_v3/bb9ff8f947e0437def74fe56e70f2fd9.svg)



举个例子：

> 用户提问：「如何快速训练一个文本分类模型？」
>
> 初步向量检索返回：
>
> 1. 文本分类的数据预处理技巧。
> 2. 文本生成与摘要的方法。
> 3. 深度学习在图像分类中的应用。
> 4. sklearn 的 SVM 使用教程。
>
> 此时 reranker 会“再面试一次”，给出排序如下：
>
> 1. 文本分类的数据预处理技巧。（高相关）
> 2. sklearn 的 SVM 使用教程。（中相关）
> 3. 深度学习在图像分类中的应用。（不相关）
> 4. 文本生成与摘要的方法。（不相关）
>
> 最终仅保留 Top-2 给大模型参考，大大减少“答非所问”的概率。
>

除了Reranker，还有Query Expansion（多查询扩展），也就是一个问题通过同义词扩展、问题改写（prompt-based query rewrite）或者利用 LLM 自动生成多个子问题换着法儿问，有时能搜到不同角度的答案。

## 4、小结
信息检索阶段对于RAG无疑是很重要的一环，你可以训练最先进的 LLM，但如果它检索不到关键内容，最终生成的结果也只能“编个差不多”。



关于深度学习和大模型相关的知识和前沿技术更新，请关注公众号`coting`!

<font style="color:rgb(25, 27, 31);"></font>

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748767076204-d38eec84-a324-42d8-acae-82a478282154.png)









