大家好，我准备开启一个全新的系列，来聊聊——RAG（Retrieval-Augmented Generation）系统的底层设计与工程实现。

<font style="color:rgb(25, 27, 31);">你可能已经用过各种“大模型加检索”的应用：AI 助手能秒答公司文档问题、客服机器人能一口气分析十几页合同、技术问答系统好像“查阅过全网资料”……但你有没有想过：这些模型到底是怎么“知道”你提的问题答案的？模型为什么能记住一整本文档？我们把知识库接入大模型，到底做了什么？</font>

<font style="color:rgb(25, 27, 31);">这一切的背后，离不开三个字母：</font>**RAG**<font style="color:rgb(25, 27, 31);">。</font>

<font style="color:rgb(25, 27, 31);">这个系列将拆解构建一个 RAG 系统的全流程，深入剖析每个关键步骤的逻辑、技术选型与工程落地难点：</font>

+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（一）：</font>[什么是RAG？一文搞懂检索增强生成技术](https://zhuanlan.zhihu.com/p/1912270367357122436)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（二）：</font>[一文搞懂RAG 的文档解析](https://zhuanlan.zhihu.com/p/1912549174966194672)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（三）：</font>[一文搞懂RAG 的切分策略](https://zhuanlan.zhihu.com/p/1912878600853623201)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（四）：</font>[RAG-embedding篇](https://zhuanlan.zhihu.com/p/1912910452339484544)
+ <font style="color:rgb(25, 27, 31);">RAG 实战指南（五）：</font>[RAG信息检索-如何让模型找到‘对的知识’](https://zhuanlan.zhihu.com/p/1912920089109430794)

<font style="color:rgb(25, 27, 31);">此外，所有相关源码示例、流程图、模型配置与知识库构建技巧，我也将持续更新在 Github：</font>[**<font style="color:rgb(25, 27, 31);">LLMHub</font>**](https://github.com/zhangting-hit/LLMHub)<font style="color:rgb(25, 27, 31);">，欢迎关注收藏！</font>

## <font style="color:rgb(25, 27, 31);">1.前言</font>
在大语言模型（LLM）如ChatGPT、Claude、Gemini日益强大的今天，人们希望它们不仅能“生成”，还要“准确生成”。然而，LLM训练的数据往往是静态的、封闭的，这使得它们在面对**时效性强、专业性高、上下文复杂**的问题时，力不从心。

在有些时候，企业内部或者事业部门内部的数据是不允许公开上传的，那么也就没有办法享受到大模型的服务，生产力也得不到解放。

这时，RAG（Retrieval-Augmented Generation，检索增强生成）应运而生。它是连接“生成能力”与“外部知识”的桥梁，让LLM不再是“闭门造车”，而成为真正的知识型智能体。

关于RAG的介绍可以参考[什么是RAG？一文搞懂检索增强生成技术](https://zhuanlan.zhihu.com/p/1912270367357122436)。

对于RAG来说，最重要的无疑是从文档中提取内容作为知识库，所以从文档中提取得到高质量的数据至关重要。

从计算机的角度来看，文档主要分为两类：

+ **有标记的文档**：如Word,Markdown,HTML,JSON等，这些文档具有明确的结构，计算机可以直接解析和理解。
+ **无标记的文档：**如图像，pdf等，这些文档缺乏结构信息，计算机无法直接理解其内容。

下面介绍当下对pdf文件进行解析的方法。

## 2.pdf解析难点
pdf是一种和docx以及doc文档一样最常见的文档格式。以下介绍和分析以[gpt3](https://arxiv.org/pdf/2005.14165)论文中的第9页为例。



![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748748210022-307fa94f-af59-47f5-aa6a-8c702e01951b.png)

尽管 PDF（Portable Document Format）是一种通用、稳定、跨平台的文档格式，但它**并不是为结构化数据提取设计的格式**，这也使得从中提取高质量、结构化的知识成为一项技术挑战。主要难点包括：

#### 1. **格式复杂、结构不统一**
PDF 文件更像是“数字版的打印纸张”，其本质是**页面渲染信息**，而不是像 HTML、XML 那样的结构化标记语言。这导致同样是一个段落或表格，不同的 PDF 文件可能用完全不同的底层表示方式来编码。因此：

+ 标题和正文没有语义上的“层级结构”；
+ 表格、列表、图像和段落难以准确分离；
+ 多栏排版、复杂排版（如学术论文）易导致文本顺序错乱。

#### 2. **内容可能是图片而非文本**
许多扫描版文档（如合同、书籍、报表等）将内容以**图像形式嵌入 PDF**，此时需要 OCR（Optical Character Recognition，光学字符识别）工具进行识别，但 OCR：

+ 容易受图像质量、字体、旋转角度等因素影响；
+ 误识率高，可能产生错别字或结构错位；
+ 表格、公式识别精度更低。

#### 3. **表格、图表提取困难**
PDF 中的表格通常以线段 + 文本方式绘制，并非内嵌结构表格数据。这导致表格提取需依赖：

+ 文字坐标分析；
+ 网格线推断；
+ 机器学习辅助模型等。  
而图表（如折线图、饼图）更难提取出其中的**数据值**，往往只能通过图像分析手段尝试“反推”。

#### 4. **跨页内容难以关联**
如长段落、长表格跨越多个页面时，PDF 中并没有“语义信息”标明它们属于同一个结构，需人工或智能算法识别其上下文关联性。

#### 5. **不同语言、字体、排版标准差异**
特别是在多语种文档处理（如中英文混排、右到左语言等）中，不同语言的排版逻辑和标点规则可能导致解析工具无法正确断句、分段，影响后续向量化建库质量。

## 3.基于规则的方法
 这是最早期也是最基础的 PDF 解析思路，依赖 PDF 文档的结构信息（如页数、文本框、字体大小、位置等），通过**手动设计规则**提取内容。以 Python 中的 `PyPDF2` 或 `PyPDF4` 为代表，它们支持读取 PDF 文件中的文本、页码、元信息等。  以最基础的PyPDF库为例进行介绍。



![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748748570573-c1864a80-02e1-4095-b55d-e56346f04e3d.png)



从图中的分析结果可以看到，PyPDF不对图片进行识别，输出的格式只支持txt，并且在文档换行的时候对应的识别结果也出现换行，段落完整性较差。

类似的基于**规则**的方法还有PyMuPDF等等， 这种方法适用于对文档结构非常了解的场景，如内部模板化文档、批量合同抽取等。  

## 4.基于深度学习的方法
为了解决规则方法在结构复杂文档中的局限，近年来出现了以 **深度学习模型** 为核心的解析方法。典型代表如 `LayoutParser`、`Donut`、`DocTR` 等，结合图像分割、目标检测模型，对 PDF 页面进行版面分析（Layout Analysis），**流程大致如下**：

    1. 将 PDF 页面渲染为图像；
    2. 使用模型识别出页面中的“标题”“段落”“表格”“图像”等区块；
    3. 再使用 OCR 对每个区块进行文本识别；
    4. 结合位置、标签进行结构化重构。

以PaddleOCR团队自研的智能文档分析系统<font style="color:rgb(86, 87, 114);">PP-StructureV2</font>为例，系统首先经过图像矫正模块，判断图方向并完成转正，随后进行版面信息分析和关键信息抽取。图像经过版面分析模型对文件不同区域进行划分，包括文本，图像，表格等等，随后对不同的区域进行识别，最后使用版面恢复将其恢复为与原始文件布局一致的文件中。

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748762960084-a06668b0-3a45-4c6d-84c7-cd8a833f1825.png)



![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748762588835-2321aa4e-dd63-47d3-a047-f0a6255f400b.png)![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748762588471-59b9e00c-efc5-4f42-b89b-6593a0b5a1c1.png)

从上面的识别结果可以看出，相比于基于规则的识别方法，深度学习方法段落完整性较好，可适应多种布局；模型可迁移至各类文档（论文、发票、报告等）；但是表格识别和图像识别仍然不够准确，同时需依赖 GPU 计算资源，对于语义理解和上下文推理仍然有限。

## 5.基于多模态大模型的方法
随着多模态大模型的发展，PDF 内容解析开始进入“端到端智能理解”阶段。这类方法利用图文输入能力强大的模型（如 GPT-4V、Gemini、Claude、MiniGPT-4），**直接输入页面截图或文档图片**，由大模型进行内容提取与理解。**典型方式**<font style="color:rgb(25, 27, 31);">如下：</font>

    1. <font style="color:rgb(25, 27, 31);">将 PDF 渲染成图像；</font>
    2. <font style="color:rgb(25, 27, 31);">提问如：“请总结这页的主要内容”“这页的表格中第一列是什么含义”；</font>
    3. <font style="color:rgb(25, 27, 31);">LMM 模型结合视觉+语言能力返回结构化或自然语言内容。</font>

<font style="color:rgb(25, 27, 31);">以Qwen2.5-VL系列模型为例，</font><font style="color:rgb(31, 31, 31);">在 Qwen2.5-VL 中设计了一种更全面的文档解析格式，称为 QwenVL HTML 格式，它既可以将文档中的文本精准地识别出来，也能够提取文档元素（如图片、表格等）的位置信息，从而准确地将文档中的版面布局进行精准还原。</font>

<font style="color:rgb(25, 27, 31);"></font>

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748765564653-3d2afde0-9ad3-4cab-a3d0-9b777b09d509.png)

多模态模型**无需预定义规则或模型训练**，能处理复杂结构、跨页关联、图表内容，并支持语义级别的问答、摘要、推理。但是成本高（API调用或推理资源），对上下文窗口长度、图像清晰度等有一定要求。



内容部分参考

[2024年 PP-Structure 快速入门 - 飞桨AI Studio星河社区](https://aistudio.baidu.com/projectdetail/8365674)

[Qwen2.5 VL!](https://qwenlm.github.io/zh/blog/qwen2.5-vl/)

[LLM之RAG实战（二十九）| 探索RAG PDF解析](https://zhuanlan.zhihu.com/p/686844517#:~:text=%E6%9C%AC%E6%96%87%E4%B8%BB%E8%A6%81%E4%BB%8B%E7%BB%8D%E8%A7%A3%E6%9E%90PDF%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%8C%E4%B8%BA%E6%9C%89%E6%95%88%E8%A7%A3%E6%9E%90PDF%E6%96%87%E6%A1%A3%E5%92%8C%E6%8F%90%E5%8F%96%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%A4%9A%E7%9A%84%E6%9C%89%E7%94%A8%E4%BF%A1%E6%81%AF%E6%8F%90%E4%BE%9B%E4%BA%86%E7%AE%97%E6%B3%95%E5%92%8C%E5%8F%82%E8%80%83%E3%80%82%20PDF%E6%96%87%E6%A1%A3%E6%98%AF%E9%9D%9E%E7%BB%93%E6%9E%84%E5%8C%96%E6%96%87%E6%A1%A3%E7%9A%84%E4%BB%A3%E8%A1%A8%EF%BC%8C%E7%84%B6%E8%80%8C%EF%BC%8C%E4%BB%8EPDF%E6%96%87%E6%A1%A3%E4%B8%AD%E6%8F%90%E5%8F%96%E4%BF%A1%E6%81%AF%E6%98%AF%E4%B8%80%E4%B8%AA%E5%85%B7%E6%9C%89%E6%8C%91%E6%88%98%E6%80%A7%E7%9A%84%E8%BF%87%E7%A8%8B%E3%80%82,%E5%B0%86PDF%E6%8F%8F%E8%BF%B0%E4%B8%BA%E8%BE%93%E5%87%BA%E6%8C%87%E4%BB%A4%E7%9A%84%E9%9B%86%E5%90%88%E6%9B%B4%E5%87%86%E7%A1%AE%EF%BC%8C%E8%80%8C%E4%B8%8D%E6%98%AF%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E3%80%82%20PDF%E6%96%87%E4%BB%B6%E7%94%B1%E4%B8%80%E7%B3%BB%E5%88%97%E6%8C%87%E4%BB%A4%E7%BB%84%E6%88%90%EF%BC%8C%E8%BF%99%E4%BA%9B%E6%8C%87%E4%BB%A4%E6%8C%87%E7%A4%BAPDF%E9%98%85%E8%AF%BB%E5%99%A8%E6%88%96%E6%89%93%E5%8D%B0%E6%9C%BA%E5%9C%A8%E5%B1%8F%E5%B9%95%E6%88%96%E7%BA%B8%E5%BC%A0%E4%B8%8A%E6%98%BE%E7%A4%BA%E7%AC%A6%E5%8F%B7%E7%9A%84%E4%BD%8D%E7%BD%AE%E5%92%8C%E6%96%B9%E5%BC%8F%EF%BC%8C%E8%BF%99%E4%B8%8EHTML%E5%92%8Cdocx%E7%AD%89%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E5%BD%A2%E6%88%90%E5%AF%B9%E6%AF%94%EF%BC%8C%E5%90%8E%E8%80%85%E4%BD%BF%E7%94%A8%3Cp%3E%E3%80%81%3Cw%3Ap%3E%E3%80%81%3Ctable%3E%E5%92%8C%3Cw%3Atbl%3E%E7%AD%89%E6%A0%87%E8%AE%B0%E6%9D%A5%E7%BB%84%E7%BB%87%E4%B8%8D%E5%90%8C%E7%9A%84%E9%80%BB%E8%BE%91%E7%BB%93%E6%9E%84%EF%BC%8C%E5%A6%82%E5%9B%BE2%E6%89%80%E7%A4%BA%EF%BC%9A%20%E8%A7%A3%E6%9E%90PDF%E6%96%87%E6%A1%A3%E7%9A%84%E6%8C%91%E6%88%98%E5%9C%A8%E4%BA%8E%E5%87%86%E7%A1%AE%E6%8F%90%E5%8F%96%E6%95%B4%E4%B8%AA%E9%A1%B5%E9%9D%A2%E7%9A%84%E5%B8%83%E5%B1%80%EF%BC%8C%E5%B9%B6%E5%B0%86%E5%8C%85%E6%8B%AC%E8%A1%A8%E6%A0%BC%E3%80%81%E6%A0%87%E9%A2%98%E3%80%81%E6%AE%B5%E8%90%BD%E5%92%8C%E5%9B%BE%E5%83%8F%E5%9C%A8%E5%86%85%E7%9A%84%E5%86%85%E5%AE%B9%E7%BF%BB%E8%AF%91%E6%88%90%E6%96%87%E6%A1%A3%E7%9A%84%E6%96%87%E6%9C%AC%E8%A1%A8%E7%A4%BA%E3%80%82)

[文档解析与向量化技术加速 RAG 应用落地_AI&大模型_InfoQ精选文章](https://www.infoq.cn/article/SEdrDVfZPxDyutR4Asqm)

非常感谢，如有侵权请联系删除！



<font style="color:rgb(31, 35, 40);">更多相关资料在github中，系统整理与分享大语言模型（LLM）相关的核心知识、面试内容、实际应用场景及部署技巧。内容涵盖从基础概念、主流模型对比、Prompt 设计、模型微调到工程部署的完整流程，帮助开发者、研究者以及求职者高效掌握大模型领域的关键能力。</font>

[GitHub - zhangting-hit/LLMHub: 本项目旨在系统整理与分享大语言模型（LLM）相关的核心知识、面试内容、实际应用场景及部署技巧。内容涵盖从基础概念、主流模型对比、Prompt 设计、模型微调到工程部署的完整流程，帮助开发者、研究者以及求职者高效掌握大模型领域的关键能力。](https://github.com/zhangting-hit/LLMHub)

关于深度学习和大模型相关的知识和前沿技术更新，请关注公众号`coting`!



![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748767076204-d38eec84-a324-42d8-acae-82a478282154.png)



