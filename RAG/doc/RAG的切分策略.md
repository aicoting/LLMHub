RAG飞速发展，成为连接“生成能力”与“外部知识”的桥梁，关于RAG的介绍可以参考[什么是RAG？一文搞懂检索增强生成技术](https://zhuanlan.zhihu.com/p/1912270367357122436)。

前面我们介绍了RAG系统中的文档解析，[RAG 的文档解析：PDF 篇](https://zhuanlan.zhihu.com/p/1912549174966194672)，在解析文档得到数据后，由于数据规模很可能非常庞大，整体存储具有难度，并且在查询的时候可能仅仅和其中的一个或几个段落有关系，所以需要分块技术将解析后的文档内容切分为适当的片段。

在RAG系统的构建中，文档切分策略很大程度上决定着模型检索质量，切分的好，信息命中更精准，生成回答更有上下文逻辑；切分的差，AI或许会变成“口吃患者”。

分块技术在实际应用中面临诸多挑战。首先是**如何选择合适的分块粒度**。如果分块过大，模型在检索时可能会引入大量无关信息，影响回答的精准度；如果分块过小，又可能导致上下文被打断，使得模型缺乏完整语义，难以理解用户问题的背景。

其次，**语义完整性**是一个核心问题。很多文档结构并非严格按段落划分语义，尤其在技术文档、法律条款或科研论文中，一个重要的论点可能跨越多个段落甚至页码。简单按长度切分容易打断逻辑，导致模型“读到的”和“作者要表达的”不是一回事。

下面，我介绍一下5种RAG切分策略。

![](https://cdn.nlark.com/yuque/0/2025/gif/28454971/1748843318161-ca765bee-a164-4e18-b173-734d30a241c9.gif)

## 1.固定大小切分
 将文档按照预设的字符数、词数或句子数进行等间隔划分。例如每段包含500个字符或5个句子。该方法实现简单，但容易打断语义边界，可能导致上下文缺失或内容重复。  

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748844065422-74be7984-5e7a-4924-abe5-b68e3071f0c3.png)

## 2.语义切分
 通过自然语言处理技术（如句向量相似度、话题建模等）判断文本语义的边界，在语义上自然断句。

![](https://cdn.nlark.com/yuque/0/2025/gif/28454971/1748844093540-d11377cd-f759-4b59-8bbc-7c295400b48a.gif)

以向量相似度为例，将句子或段落转换为向量，通过计算相邻句段的余弦相似度，如果判断两个段落语义上属于同一单元，那么就进行合并。  

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748844114766-be34cf6e-3d12-4260-b50e-0aea676f6461.png)

这种方式能提升分块的语义连贯性，适用于逻辑紧密的文章，但计算代价较高，依赖模型质量。  

## 3.递归切分
![](https://cdn.nlark.com/yuque/0/2025/gif/28454971/1748844131608-4939be78-8a95-4953-afb7-8e38b6d784ac.gif)

在保持固定长度的同时，尝试以语义结构（如段落、句子、标点）为边界递归地切分文本。若段落太长无法容纳于块中，则再递归切分为句子，直到满足长度要求。

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748844161027-9ede529c-f917-4c38-b239-3a09a99aa352.png)

相比纯固定切分，该方法能更好地保留语义完整性。  

## 4.基于文档结构的切分
![](https://cdn.nlark.com/yuque/0/2025/gif/28454971/1748844169909-d4a92783-5303-4891-b8c2-a21bd48d88f9.gif)

利用原始文档的结构信息（如HTML标签、Markdown标题、PDF书签、Word段落等）进行切分。比如以章节、小标题、列表项为边界进行分块。

![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748844187819-30c45585-7206-49fc-be0d-0495e989801d.png)

这种方式在处理格式规范的文档（如手册、报告）时效果尤为突出。  

## 5.基于LLM的切分
![](https://cdn.nlark.com/yuque/0/2025/gif/28454971/1748844197347-6531fcb9-c4df-4287-9dfe-988a008a51ae.gif)

 借助大语言模型来“理解”文档内容并主动划定分块边界。例如，提示模型判断哪些段落构成完整的语义单元，或根据任务需求生成最佳的分块方案。这种方式智能程度高，但计算成本也相对较大，适合高精度应用场景。 

## 6.总结
 实际应用中，往往需要结合多种策略，根据数据类型和业务需求灵活调整，以构建既高效又精准的 RAG 系统。  



如果想形象的理解一下分块，可以使用在线的分块可视化工具[ChunkViz](https://chunkviz.up.railway.app/)进行体验。



文中的图片来自

[图解 RAG 的 5 种分块策略 - 53AI-AI知识库|大模型知识库|大模型训练|智能体开发](https://www.53ai.com/news/RAG/2025060181652.html)

[5 Chunking Strategies For RAG](https://blog.dailydoseofds.com/p/5-chunking-strategies-for-rag-f8b)

非常感谢，如有侵权请联系删除！



<font style="color:rgb(31, 35, 40);">更多相关资料在github中，系统整理与分享大语言模型（LLM）相关的核心知识、面试内容、实际应用场景及部署技巧。内容涵盖从基础概念、主流模型对比、Prompt 设计、模型微调到工程部署的完整流程，帮助开发者、研究者以及求职者高效掌握大模型领域的关键能力。</font>

[GitHub - zhangting-hit/LLMHub: 本项目旨在系统整理与分享大语言模型（LLM）相关的核心知识、面试内容、实际应用场景及部署技巧。内容涵盖从基础概念、主流模型对比、Prompt 设计、模型微调到工程部署的完整流程，帮助开发者、研究者以及求职者高效掌握大模型领域的关键能力。](https://github.com/zhangting-hit/LLMHub)

关于深度学习和大模型相关的知识和前沿技术更新，请关注公众号`coting`!



![](https://cdn.nlark.com/yuque/0/2025/png/28454971/1748767076204-d38eec84-a324-42d8-acae-82a478282154.png)

