<!--
 * @Author: zhangting
 * @Date: 2025-05-22 11:37:41
 * @LastEditors: Do not edit
 * @LastEditTime: 2025-06-22 10:01:55
 * @FilePath: /zhangting/LLMHub/README.md
-->
# LLMHub
![image](./img/LLMHub.png)
本项目旨在系统整理与分享深度学习与大语言模型（LLM）相关的核心知识、面试内容、实际应用场景及部署技巧。内容涵盖从基础概念、主流模型对比、Prompt 设计、模型微调到工程部署的完整流程，帮助开发者、研究者以及求职者高效掌握大模型领域的关键能力。

![image](./img/development_of_llm.png)

## 目录
- 📚 [计算机专业基础知识](./计算机专业基础知识/)
    - 📗 [计算机网络](./计算机专业基础知识/计算机网络.md)
    - 📘 [操作系统](./计算机专业基础知识/操作系统.md)
    - 📙 [数据库系统](./计算机专业基础知识/数据库系统.md)
- 🖥️ [开发](./开发/)
    - 🐍 [Python知识点](./开发/Python知识点.md)
- 🐫 [深度学习](./deep-learning/)
    - 🐱 [神经网络](./deep-learning/神经网络/)
        - 😼[神经网络到底是什么？它是如何“模仿人脑”的？](./deep-learning/神经网络/什么是神经网络.md)
        - 😽[什么是梯度下降？为什么梯度下降能优化模型？](./deep-learning/神经网络/什么是梯度下降？为什么梯度下降能优化模型？.md)
        - 🙀[什么是反向传播？](./deep-learning/神经网络/什么是反向传播？.md)
        - 😻[如何用代码手写一个简单的神经网络，从0开始训练识别手写数字？](./deep-learning/神经网络/从0开始训练识别手写数字.md)
    - 🪄 [经典模型](./deep-learning/经典模型/)
        - 🐎 [RNN原理](./deep-learning/经典模型/RNN.md)
        - 🐏 [LSTM&GRU原理](./deep-learning/经典模型/LSTM&GRU.md)
        - 🦈 [Transformer原理](./deep-learning/经典模型/Transformer.md)
            - 🐳[一览Transformer整体架构](./deep-learning/经典模型/transformer/一览Transformer整体架构.md)
            - 🐋[Transformer——Attention怎么实现集中注意力](./deep-learning/经典模型/transformer/Transformer——Attention怎么实现集中注意力.md)
            - 🐬[Transformer——FeedForward模块在干什么？](./deep-learning/经典模型/transformer/Transformer——FeedForward模块在干什么？.md)
            - 🐟[从0开始实现Transformer](./deep-learning/经典模型/transformer/从0开始实现Transformer.md)
        - 🦋 [Bert原理](./deep-learning/经典模型/Bert.md)
    - 🐹 [基础知识](./deep-learning/基础知识.md)
    - 💽 [硬件加速库](./deep-learning/加速计算支持层（硬件加速库）.md)
- 🦜 [大模型](./大模型)
    - 📚 [基础知识](./大模型/基础知识.md)
    - 📄 [协议](./协议/)
        - 📄 [MCP](./协议/大模型背后的协议与接口设计（一）-%20%20MCP.md)
    - ⌨ [微调技术](./大模型/微调技术/)
        - 🏃‍ [DeepSpeed原理](./大模型/微调技术/DeepSpeed.md)
        - 🏊‍ [LORA原理](./大模型/微调技术/LORA.md)
    - 🧐 [RAG](./RAG/doc/)
        - 🦋 [什么是RAG？一文搞懂检索增强生成技术](./大模型/RAG/doc/什么是RAG？一文搞懂检索增强生成技术.md)
        - 🤗[一文搞懂RAG 的文档解析](./大模型/RAG/doc/一文搞懂RAG%20的文档解析.md)
        - 🙂[一文搞懂RAG的切分策略](./大模型/RAG/doc/一文搞懂RAG的切分策略.md)
        - 😮[RAG-embedding篇](./大模型/RAG/doc/RAG-embedding篇.md)
        - 😜[RAG 信息检索：如何让模型找到‘对的知识’](./大模型/RAG/doc/RAG%20信息检索：如何让模型找到‘对的知识’.md)
    - 📑 [Data-Juicer原理及使用](./大模型/Data-Juicer.md)


正在更新ing，如果小伙伴对其他内容感兴趣欢迎联系我们😊😊！


如有侵权请联系删除。

微信公众号：*算法coting*，该公众号主要分享深度学习与大语言模型（LLM）相关的核心知识、面试内容、实际应用场景及部署技巧等。


![image](./img/微信公众号.png)


